origin <- read.csv("cluster_origin_10.csv")                      # 182,  8
tmap <- read.csv("cluster_tmap.csv")                             # 15,   8
virtual <- read.csv("cluster_virtual.csv")                       # 1248, 8
new <- read.csv("cluster_new.csv")                               # 12,   8
x_train <- origin[, -4]
y_train <- origin[, 4]
x_test <- tmap[, -4]
y_test <- tmap[, 4]
# training with train data
#model <- svm(x_train, y_train, type = "nu-regression")
model <- svm(x_train, y_train)
summary(model)
# test with test data
pred <- predict(model, x_test)
pred <- round(pred, 1)
## compare with real answer
compare <- cbind(x_test[,], pred, y_test, abs(pred-y_test))
colnames(compare) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","clust_car","clust_cdr","clust_adr","pred", "answer", "loss")
compare
## calculate RMSE
RMSE <- sqrt( sum( ( pred-y_test )^2 )  / nrow(compare) )
RMSE
## model = origin // data = tmap & virtual // goal = data's result prediction
## SVM
rm(list=ls())
library(e1071)
origin <- read.csv("cluster_origin_10.csv")                      # 182,  8
tmap <- read.csv("cluster_tmap.csv")                             # 15,   8
virtual <- read.csv("cluster_virtual.csv")                       # 1248, 8
new <- read.csv("cluster_new.csv")                               # 12,   8
x_train <- origin[, -4]
y_train <- origin[, 4]
x_test <- virtual[, -4]
y_test <- virtual[, 4]
# training with train data
#model <- svm(x_train, y_train, type = "nu-regression")
model <- svm(x_train, y_train)
summary(model)
# test with test data
pred <- predict(model, x_test)
pred <- round(pred, 1)
## compare with real answer
compare <- cbind(x_test[,], pred, y_test, abs(pred-y_test))
colnames(compare) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","clust_car","clust_cdr","clust_adr","pred", "answer", "loss")
compare
## calculate RMSE
RMSE <- sqrt( sum( ( pred-y_test )^2 )  / nrow(compare) )
RMSE
rm(list=ls())
library(keras)
library(MASS)
use_session_with_seed(1, disable_parallel_cpu = FALSE)
## read csv file for model
m_score <- read.csv("cluster_origin_10.csv")
## read csv file for data
d_score <- read.csv("cluster_virtual.csv")
x_train <- as.matrix(m_score[, -4])
y_train <- as.matrix(m_score[, 4])
x_test <- as.matrix(d_score[, -4])
y_test <- as.matrix(d_score[, 4])
# create model
model = keras_model_sequential()
model %>%
layer_dense(input_shape = ncol(x_train), units = 128, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1)
summary(model)
# create model
model = keras_model_sequential()
model %>%
layer_dense(input_shape = ncol(x_train), units = 128, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1)
summary(model)
# add a loss function and optimizer
model %>%
compile(
loss = "logcosh",
optimizer = "Nadam",
metrics = list("mean_absolute_error")
)
fit = model %>%
fit(
x = x_train,
y = y_train,
batch_size = 256,
epochs = 3000
)
# Training and evaluation
model %>% evaluate(x_test, y_test, verbose = 1)
# print predicted value
pred = model %>% predict(x_test)
result <- cbind(x_test[,], pred, y_test, pred-y_test)
colnames(result) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","pred", "answer", "loss")
colnames(result) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","clust_car","clust_cdr","clust_adr","pred", "answer", "loss")
result
## calculate RMSE
RMSE <- sqrt( sum( ( pred-y_test )^2 )  / nrow(result) )
RMSE
## read csv file for data
d_score <- read.csv("cluster_new.csv")
x_test <- as.matrix(d_score[, -4])
y_test <- as.matrix(d_score[, 4])
# Training and evaluation
model %>% evaluate(x_test, y_test, verbose = 1)
# print predicted value
pred = model %>% predict(x_test)
result <- cbind(x_test[,], pred, y_test, pred-y_test)
colnames(result) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","clust_car","clust_cdr","clust_adr","pred", "answer", "loss")
result
## calculate RMSE
RMSE <- sqrt( sum( ( pred-y_test )^2 )  / nrow(result) )
RMSE
## read csv file for data
d_score <- read.csv("cluster_tmap.csv")
x_train <- as.matrix(m_score[, -4])
y_train <- as.matrix(m_score[, 4])
x_test <- as.matrix(d_score[, -4])
y_test <- as.matrix(d_score[, 4])
# Training and evaluation
model %>% evaluate(x_test, y_test, verbose = 1)
# print predicted value
pred = model %>% predict(x_test)
result <- cbind(x_test[,], pred, y_test, pred-y_test)
colnames(result) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","clust_car","clust_cdr","clust_adr","pred", "answer", "loss")
result
## calculate RMSE
RMSE <- sqrt( sum( ( pred-y_test )^2 )  / nrow(result) )
RMSE
setwd("D:/WorkSpace/R/R_code/0203")
rm(list=ls())
library(keras)
library(MASS)
use_session_with_seed(1, disable_parallel_cpu = FALSE)
## read csv file for model
m_score <- read.csv("driving_score_180ea_modify.csv")
## read csv file for data
d_score <- read.csv("tmp_data.csv")
dim(m_score)
dim(d_score)
x_train <- as.matrix(m_score[, -4])
y_train <- as.matrix(m_score[, 4])
x_test <- as.matrix(d_score[, -4])
y_test <- as.matrix(d_score[, 4])
# create model
model = keras_model_sequential()
model %>%
layer_dense(input_shape = ncol(x_train), units = 128, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1)
# create model
model = keras_model_sequential()
model %>%
layer_dense(input_shape = ncol(x_train), units = 128, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dropout(rate = 0.05) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1)
summary(model)
# add a loss function and optimizer
model %>%
compile(
loss = "logcosh",
optimizer = "Nadam",
metrics = list("mean_absolute_error")
)
fit = model %>%
fit(
x = x_train,
y = y_train,
batch_size = 256,
epochs = 3000
)
# Training and evaluation
model %>% evaluate(x_test, y_test, verbose = 1)
# print predicted value
pred = model %>% predict(x_test)
result <- cbind(x_test[,], pred, y_test, pred-y_test)
colnames(result) <- c("compl","accel","decel","pred", "answer", "loss")
result
## calculate RMSE
RMSE <- sqrt( sum( ( pred-y_test )^2 )  / nrow(result) )
RMSE
write.csv(result, "4col_149ea_virtual.csv")
setwd("D:/WorkSpace/R/R_code")
rm(list=ls())
library("NbClust")
#m_data <- read.csv("driving_score_virtual_rep.csv")
m_data <- read.csv("data_origin_149.csv")
plot(m_data)
head(m_data)
dim(m_data)
v_data <- scale(m_data[, c(-2, -3)]) ## result & compliance
t_data <- scale(m_data[, c(-1, -3)]) ## result & acceleration
s_data <- scale(m_data[, c(-1, -2)]) ## result & deceleration
## compliance & result clustering result
rst2 <- kmeans(v_data, centers=2, iter.max = 1000, nstart = 2, algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"))
rst2
## acceleration & result clustering result
rst3 <- kmeans(t_data, centers=19, iter.max = 1000, nstart = 2, algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"))
rst3
## deceleration & result clustering result
rst4 <- kmeans(s_data, centers=4, iter.max = 1000, nstart = 2, algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"))
rst4
#clust1 <- rst1[1]
clust2 <- rst2[1]
cr_nbclust <- NbClust(v_data, distance = "euclidean",
min.nc = 2, max.nc = 20,
method = "kmeans")
ar_nbclust <- NbClust(t_data, distance = "euclidean",
min.nc = 2, max.nc = 20,
method = "kmeans")
dr_nbclust <- NbClust(s_data, distance = "euclidean",
min.nc = 2, max.nc = 20,
method = "kmeans")
## compliance & result clustering result
rst2 <- kmeans(v_data, centers=18, iter.max = 1000, nstart = 2, algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"))
rst2
## acceleration & result clustering result
rst3 <- kmeans(t_data, centers=4, iter.max = 1000, nstart = 2, algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"))
rst3
## deceleration & result clustering result
rst4 <- kmeans(s_data, centers=2, iter.max = 1000, nstart = 2, algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"))
rst4
#clust1 <- rst1[1]
clust2 <- rst2[1]
clust3 <- rst3[1]
clust4 <- rst4[1]
#rsult <- cbind(m_data, clust1, clust2, clust3, clust4)
rsult <- cbind(m_data, clust2, clust3, clust4)
write.csv(rsult, "cluster_origin_149.csv")
origin <- read.csv("cluster_origin_149.csv")
head(origin)
dim(origin)
rm(list=ls())
require(class)
## Preparing training data set
train_data <- read.csv("cluster_origin_149.csv")
head(train_data)
## for cr cluster
tr_x3 <- train_data[, -c(4:7)]
## for ar cluster
tr_x2 <- train_data[, -c(4:7)]
## for dr cluster
tr_x1 <- train_data[, -c(4:7)]
## cluster_cr
tr_y3 <- train_data[, 5]
## cluster_ar
tr_y2 <- train_data[, 6]
## cluster_dr
tr_y1 <- train_data[, 7]
## Preparing Tmap data set - 15ea, k=3
test1_data <- read.csv("Tmap_data.csv")
ts1 <- test1_data[, -4]
## Preparing Virtual data set - 182 , k=13
test2_data <- read.csv("driving_score_180ea.csv")
ts2 <- test2_data[, -4]
## Preparing new data set - 13 , k=3
test3_data <- read.csv("driving_score_new.csv")
ts3 <- test3_data[, -4]
## Classification Tmap - cluster cr
cluster3 <- knn(train = tr_x3, test = ts1, cl = tr_y3, k=3, prob=TRUE)
cluster3
## Classification Tmap - cluster ar
cluster2 <- knn(train = tr_x2, test = ts1, cl = tr_y2, k=3, prob=TRUE)
cluster2
## Classification Tmap - cluster dr
cluster1 <- knn(train = tr_x1, test = ts1, cl = tr_y1, k=3, prob=TRUE)
cluster1
tmap <- cbind(test1_data, cluster3, cluster2, cluster1)
## Classification virtual - cluster cr
cluster3 <- knn(train = tr_x3, test = ts2, cl = tr_y3, k=13, prob=TRUE)
cluster3
## Classification virtual - cluster ar
cluster2 <- knn(train = tr_x2, test = ts2, cl = tr_y2, k=13, prob=TRUE)
cluster2
## Classification virtual - cluster dr
cluster1 <- knn(train = tr_x1, test = ts2, cl = tr_y1, k=13, prob=TRUE)
virtual <- cbind(test2_data, cluster3, cluster2, cluster1)
cluster1
virtual <- cbind(test2_data, cluster3, cluster2, cluster1)
## Classification new - cluster cr
cluster3 <- knn(train = tr_x3, test = ts3, cl = tr_y3, k=3, prob=TRUE)
cluster3
## Classification new - cluster ar
cluster2 <- knn(train = tr_x2, test = ts3, cl = tr_y2, k=3, prob=TRUE)
cluster2
## Classification new - cluster dr
cluster1 <- knn(train = tr_x1, test = ts3, cl = tr_y1, k=3, prob=TRUE)
cluster1
new <- cbind(test3_data, cluster3, cluster2, cluster1)
write.csv(tmap, "cluster_tmap_149.csv")
write.csv(virtual, "cluster_virtual_149.csv")
write.csv(new, "cluster_new_149.csv")
rm(list=ls())
origin <- read.csv("cluster_origin_149.csv")                         # 2000,  7
tmap <- read.csv("cluster_tmap_149.csv")                             # 15,    7
virtual <- read.csv("cluster_virtual_149.csv")                       # 182,   7
new <- read.csv("cluster_new_149.csv")                               # 12,    7
## regression
mod1 <- lm(result ~., data = origin)
## regression
mod1 <- lm(result ~., data = origin)
rm(list=ls())
origin <- read.csv("cluster_origin_149.csv")                         # 2000,  7
tmap <- read.csv("cluster_tmap_149.csv")                             # 15,    7
virtual <- read.csv("cluster_virtual_149.csv")                       # 182,   7
new <- read.csv("cluster_new_149.csv")                               # 12,    7
## regression
mod1 <- lm(result ~., data = origin)
## show model's summary
summary(mod1)
## setting data
answer <- tmap[, "result"]
compl <- tmap[, "compliance"]
accel <- tmap[, "acceleration"]
decel <- tmap[, "deceleration"]
clust3 <- tmap[, "cluster_cr"]
clust2 <- tmap[, "cluster_ar"]
clust1 <- tmap[, "cluster_dr"]
## create model
#prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] + clust3 * coef(mod1)[5] +
# clust2 * coef(mod1)[5] + clust1 * coef(mod1)[6] + clust0 * coef(mod1)[7] + coef(mod1)[1]
prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] +
clust3 * coef(mod1)[5] + clust2 * coef(mod1)[6] + clust1 * coef(mod1)[7] + coef(mod1)[1]
prediction <- round(prediction, 1)
## setting data
answer <- tmap[, "result"]
compl <- tmap[, "compliance"]
accel <- tmap[, "acceleration"]
decel <- tmap[, "deceleration"]
clust3 <- tmap[, "cluster_cr"]
clust2 <- tmap[, "cluster_ar"]
clust1 <- tmap[, "cluster_dr"]
## create model
#prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] + clust3 * coef(mod1)[5] +
# clust2 * coef(mod1)[5] + clust1 * coef(mod1)[6] + clust0 * coef(mod1)[7] + coef(mod1)[1]
prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] +
clust3 * coef(mod1)[5] + clust2 * coef(mod1)[6] + clust1 * coef(mod1)[7] + coef(mod1)[1]
prediction <- round(prediction, 1)
## setting data
answer <- tmap[, "result"]
compl <- tmap[, "compliance"]
accel <- tmap[, "acceleration"]
## setting data
answer <- tmap[, "result"]
compl <- tmap[, "compl"]
accel <- tmap[, "accel"]
decel <- tmap[, "decel"]
clust3 <- tmap[, "cluster_cr"]
clust2 <- tmap[, "cluster_ar"]
clust1 <- tmap[, "cluster_dr"]
## create model
#prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] + clust3 * coef(mod1)[5] +
# clust2 * coef(mod1)[5] + clust1 * coef(mod1)[6] + clust0 * coef(mod1)[7] + coef(mod1)[1]
prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] +
clust3 * coef(mod1)[5] + clust2 * coef(mod1)[6] + clust1 * coef(mod1)[7] + coef(mod1)[1]
prediction <- round(prediction, 1)
## compare with real answer
compare <- cbind(prediction, answer, abs(prediction-answer))
#compare <- cbind(compl, accel, decel, clust3, clust2, clust1, clust0, compare)
compare <- cbind(compl, accel, decel, clust3, clust2, clust1, compare)
#colnames(compare) <- c("compl", "accel", "decel", "clust3", "clust_cd", "clust_ca", "clust_ad", "pred", "answer", "loss")
colnames(compare) <- c("compl", "accel", "decel", "clust_cr", "clust_ar", "clust_dr", "pred", "answer", "loss")
compare
## calculate RMSE
RMSE <- sqrt( sum((prediction-answer)^2)/nrow(compare) )
RMSE
## model = origin // data = tmap & virtual // goal = data's result prediction
## DSI
rm(list=ls())
origin <- read.csv("cluster_origin_149.csv")                         # 2000,  7
tmap <- read.csv("cluster_tmap_149.csv")                             # 15,    7
virtual <- read.csv("cluster_virtual_149.csv")                       # 182,   7
new <- read.csv("cluster_new_149.csv")                               # 12,    7
## regression
mod1 <- lm(result ~., data = origin)
## show model's summary
summary(mod1)
## setting data
answer <- new[, "result"]
compl <- new[, "compl"]
accel <- new[, "accel"]
decel <- new[, "decel"]
clust3 <- new[, "cluster_cr"]
clust2 <- new[, "cluster_ar"]
clust1 <- new[, "cluster_dr"]
## create model
#prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] + clust3 * coef(mod1)[5] +
# clust2 * coef(mod1)[5] + clust1 * coef(mod1)[6] + clust0 * coef(mod1)[7] + coef(mod1)[1]
prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] +
clust3 * coef(mod1)[5] + clust2 * coef(mod1)[6] + clust1 * coef(mod1)[7] + coef(mod1)[1]
prediction <- round(prediction, 1)
## compare with real answer
compare <- cbind(prediction, answer, abs(prediction-answer))
#compare <- cbind(compl, accel, decel, clust3, clust2, clust1, clust0, compare)
compare <- cbind(compl, accel, decel, clust3, clust2, clust1, compare)
#colnames(compare) <- c("compl", "accel", "decel", "clust3", "clust_cd", "clust_ca", "clust_ad", "pred", "answer", "loss")
colnames(compare) <- c("compl", "accel", "decel", "clust_cr", "clust_ar", "clust_dr", "pred", "answer", "loss")
compare
## calculate RMSE
RMSE <- sqrt( sum((prediction-answer)^2)/nrow(compare) )
RMSE
## model = origin // data = tmap & virtual // goal = data's result prediction
## DSI
rm(list=ls())
origin <- read.csv("cluster_origin_149.csv")                         # 2000,  7
tmap <- read.csv("cluster_tmap_149.csv")                             # 15,    7
virtual <- read.csv("cluster_virtual_149.csv")                       # 182,   7
new <- read.csv("cluster_new_149.csv")                               # 12,    7
## regression
mod1 <- lm(result ~., data = origin)
## show model's summary
summary(mod1)
## setting data
answer <- virtual[, "result"]
compl <- virtual[, "compl"]
accel <- virtual[, "accel"]
decel <- virtual[, "decel"]
clust3 <- virtual[, "cluster_cr"]
clust2 <- virtual[, "cluster_ar"]
clust1 <- virtual[, "cluster_dr"]
## create model
#prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] + clust3 * coef(mod1)[5] +
# clust2 * coef(mod1)[5] + clust1 * coef(mod1)[6] + clust0 * coef(mod1)[7] + coef(mod1)[1]
prediction <- compl * coef(mod1)[2] + accel * coef(mod1)[3] + decel * coef(mod1)[4] +
clust3 * coef(mod1)[5] + clust2 * coef(mod1)[6] + clust1 * coef(mod1)[7] + coef(mod1)[1]
prediction <- round(prediction, 1)
## compare with real answer
compare <- cbind(prediction, answer, abs(prediction-answer))
#compare <- cbind(compl, accel, decel, clust3, clust2, clust1, clust0, compare)
compare <- cbind(compl, accel, decel, clust3, clust2, clust1, compare)
#colnames(compare) <- c("compl", "accel", "decel", "clust3", "clust_cd", "clust_ca", "clust_ad", "pred", "answer", "loss")
colnames(compare) <- c("compl", "accel", "decel", "clust_cr", "clust_ar", "clust_dr", "pred", "answer", "loss")
compare
## calculate RMSE
RMSE <- sqrt( sum((prediction-answer)^2)/nrow(compare) )
RMSE
## model = origin // data = tmap & virtual // goal = data's result prediction
## SVM
rm(list=ls())
library(e1071)
origin <- read.csv("cluster_origin_149.csv")                         # 2000,  7
tmap <- read.csv("cluster_tmap_149.csv")                             # 15,    7
virtual <- read.csv("cluster_virtual_149.csv")                       # 182,   7
new <- read.csv("cluster_new_149.csv")                               # 12,    7
x_train <- origin[, -4]
y_train <- origin[, 4]
x_test <- new[, -4]
y_test <- new[, 4]
# training with train data
#model <- svm(x_train, y_train, type = "nu-regression")
model <- svm(x_train, y_train)
summary(model)
# test with test data
pred <- predict(model, x_test)
pred <- round(pred, 1)
## compare with real answer
compare <- cbind(x_test[,], pred, y_test, abs(pred-y_test))
colnames(compare) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","pred", "answer", "loss")
compare
## calculate RMSE
RMSE <- sqrt( sum( ( pred-y_test )^2 )  / nrow(compare) )
RMSE
## model = origin // data = tmap & virtual // goal = data's result prediction
## RF
rm(list=ls())
library(randomForest)
origin <- read.csv("cluster_origin_149.csv")                         # 2000,  7
tmap <- read.csv("cluster_tmap_149.csv")                             # 15,    7
virtual <- read.csv("cluster_virtual_149.csv")                       # 182,   7
new <- read.csv("cluster_new_149.csv")                               # 12,    7
ds.train <- origin[,]
ds.test <- new[,]
d_score.rf <- randomForest(result ~ ., data=ds.train, ntree = 5000)
d_score.rf
d_score.pred <- predict(d_score.rf, ds.test)
d_score.pred <- round(d_score.pred, 1)
## compare with real answer
compare <- cbind(d_score.pred, ds.test[, "result"], abs(d_score.pred-ds.test[,"result"]))
compare <- cbind(ds.test[,c(1:3,5:7)], compare)
colnames(compare) <- c("compl","accel","decel","clust_cr","clust_ar","clust_dr","pred", "answer", "loss")
compare
## calculate RMSE
RMSE <- sqrt( sum( ( d_score.pred-ds.test[, "result"] )^2 )  / nrow(compare) )
RMSE
